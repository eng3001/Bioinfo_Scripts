{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa77d9b0",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of Random Forest Model\n",
    "Workflow: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "Here are the commands I used to tune the hyperparameters of the random forest model. I followed the workflow above and adjusted the commands to use a Random Forest Classifier model rather than a Random Forest Regression model. \n",
    "\n",
    "For more details on the analysis and input data createion, refer to the README file located on rustang/canopus: /home/wyatte/4DGB_ML_Random_Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25957cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in bed data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"/Users/wyatteng/Desktop/4dgb/8.9.21_RandomForest/10.18.21_CTCF_RF_Input/CTCF_4000_R1_H3K27ac_RF_Input.bed\",delimiter=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into TRAINING set and TEST set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94726da",
   "metadata": {},
   "source": [
    "## Plotting Feature Importance\n",
    "You can plot the feature importance of a Random Forest model by selecting which features you would like to compare and identify them in the 'feature_names' list. After the model is trained, you can run the plotting cell to plot the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "feature_names = ['Numreads', 'Covbases', 'Coverage', 'Meanbaseq', 'Sumdepth']\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(model.feature_importances_,index=feature_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d038c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5becc3",
   "metadata": {},
   "source": [
    "## Randomized Search (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "# Max 500\n",
    "n_estimators = [100,300,500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "# Max Depth upper limit = 30\n",
    "# 3-10, 15, 20\n",
    "max_depth = [3,4,5,6,7,8,9,10,15,20,25,30]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "# 1-16\n",
    "min_samples_leaf = [1, 2, 4, 6, 8, 10, 12, 14, 16]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56583b17",
   "metadata": {},
   "source": [
    "Fitting the following code will take a LONG time. The larger the grid, the more combinations of RF runs will be ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bac4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will output the best parameters found during the random grid search technique\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf47569",
   "metadata": {},
   "source": [
    "Best parameters from random grid:\n",
    "\n",
    "{'n_estimators': 300,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 16,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 9,\n",
    " 'bootstrap': True}\n",
    " \n",
    " The function below will print the model performance, precision, recall, and f1 score for the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe589ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(test_labels, predictions))\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    return predictions\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators = 100)\n",
    "base_model.fit(X_train, y_train)\n",
    "random_predictions = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b27d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, None]\n",
    "md_results = dict()\n",
    "accuracy_results = dict()\n",
    "for item in max_depth:\n",
    "    best_model = RandomForestClassifier(n_estimators=300,min_samples_split=5, min_samples_leaf=16, max_features='auto', max_depth=item, bootstrap=True)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    predictions = best_model.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test, predictions)\n",
    "    ac = metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "    md_results[item] = mse\n",
    "    accuracy_results[item] = ac\n",
    "    \n",
    "print(md_results)\n",
    "print(accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0563c",
   "metadata": {},
   "source": [
    "The code above fits the Random Forest model to the training dataset based on a varying max_depth. The model is then tested on the test dataset and the accuracy and mean squared error is stored in the respecting dictionaries. The plots below will visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(md_results.keys(), md_results.values())\n",
    "plt.title('MSE vs Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracy_results.keys(), accuracy_results.values())\n",
    "plt.title('Accuracy vs Max Depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12d8af",
   "metadata": {},
   "source": [
    "## Grid Search (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [3, 6, 9, 15, 20, 25, 30, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 300, 500]\n",
    "}\n",
    "# Create a based model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0074dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6b382",
   "metadata": {},
   "source": [
    "The best results I found from grid_search technique was...\n",
    "\n",
    "{'bootstrap': True,\n",
    " 'max_depth': 9,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44366fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(test_labels, predictions))\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    return predictions\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3ecfb",
   "metadata": {},
   "source": [
    "### Trying to Compare True vs Predicted\n",
    "The code below was used to manipulate the data so the predictions and true data are in the same datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_random = RandomForestClassifier(n_estimators=300,min_samples_split=5, min_samples_leaf=16, max_features='auto', max_depth=9, bootstrap=True)\n",
    "best_model = rf_random\n",
    "best_model.fit(X_train, y_train)\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc287a",
   "metadata": {},
   "source": [
    "The 'true_val' data is the the true data that is converted to a numpy.ndarray in order to match the 'predictions' data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c461d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_axis=X_test.index.values\n",
    "true_val=X_test.CTCF_Binding_Sites.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bea4a",
   "metadata": {},
   "source": [
    "I have yet to figure out a good way to compare the true and predicted data sets. The code below is a broad view of the two datasets, but it is not very informative since the X_axis is spread over a wide range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(X_axis, real_array)\n",
    "plt.plot(X_axis, predictions)\n",
    "plt.title('True vs Predicted')\n",
    "plt.xlabel('X index')\n",
    "plt.ylabel('Predicted ATAC Peaks')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
